{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U32wauQU1y55",
        "outputId": "d8958c28-2f11-4d4b-d502-86fa5c48fd09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------------------------+------------------+--------------------+---------------------+\n",
            "|   Data size | Configuration                   |   Training error |   Validation error |   Time of execution |\n",
            "+=============+=================================+==================+====================+=====================+\n",
            "|        1000 | 1 hidden layer 4 nodes          |           0.238  |             0.2528 |               0.041 |\n",
            "+-------------+---------------------------------+------------------+--------------------+---------------------+\n",
            "|       10000 | 1 hidden layer 4 nodes          |           0.0111 |             0.012  |               0.688 |\n",
            "+-------------+---------------------------------+------------------+--------------------+---------------------+\n",
            "|      100000 | 1 hidden layer 4 nodes          |           0.0006 |             0.0006 |               4.475 |\n",
            "+-------------+---------------------------------+------------------+--------------------+---------------------+\n",
            "|        1000 | 2 hidden layers of 4 nodes each |           0.226  |             0.238  |               0.044 |\n",
            "+-------------+---------------------------------+------------------+--------------------+---------------------+\n",
            "|       10000 | 2 hidden layers of 4 nodes each |           0.2376 |             0.238  |               0.186 |\n",
            "+-------------+---------------------------------+------------------+--------------------+---------------------+\n",
            "|      100000 | 2 hidden layers of 4 nodes each |           0.0006 |             0.0007 |               9.212 |\n",
            "+-------------+---------------------------------+------------------+--------------------+---------------------+\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import time\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Load and prepare data\n",
        "pima_df = pd.read_csv(\"pima_synthetic.csv\")\n",
        "X = pima_df.drop('outcome', axis=1)\n",
        "y = pima_df['outcome']\n",
        "\n",
        "# Split data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# Function to create datasets of different sizes\n",
        "def create_dataset(X, y, size):\n",
        "    if size > len(X):\n",
        "        # If requested size is larger, use data augmentation with noise\n",
        "        factor = int(np.ceil(size / len(X)))\n",
        "        X_aug = np.tile(X, (factor, 1))\n",
        "        y_aug = np.tile(y, factor)\n",
        "        # Add small random noise to augmented data\n",
        "        noise = np.random.normal(0, 0.01, X_aug.shape)\n",
        "        X_aug = X_aug + noise\n",
        "        return X_aug[:size], y_aug[:size]\n",
        "    else:\n",
        "        return X[:size], y[:size]\n",
        "\n",
        "# Configurations to test\n",
        "configs = [\n",
        "    (1000, (4,), \"1 hidden layer 4 nodes\"),\n",
        "    (10000, (4,), \"1 hidden layer 4 nodes\"),\n",
        "    (100000, (4,), \"1 hidden layer 4 nodes\"),\n",
        "    (1000, (4, 4), \"2 hidden layers of 4 nodes each\"),\n",
        "    (10000, (4, 4), \"2 hidden layers of 4 nodes each\"),\n",
        "    (100000, (4, 4), \"2 hidden layers of 4 nodes each\")\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for data_size, hidden_layers, config_name in configs:\n",
        "    # Create training dataset of specified size\n",
        "    X_train_subset, y_train_subset = create_dataset(X_train_scaled, y_train, data_size)\n",
        "\n",
        "    # Create and train model\n",
        "    model = MLPClassifier(\n",
        "        hidden_layer_sizes=hidden_layers,\n",
        "        activation='relu',  # Fast and effective activation function\n",
        "        solver='adam',      # Efficient solver\n",
        "        max_iter=100,       # Limit iterations for speed\n",
        "        random_state=42,\n",
        "        early_stopping=True,  # Stop early if validation performance plateaus\n",
        "        n_iter_no_change=5,\n",
        "        validation_fraction=0.1  # Use small internal validation set\n",
        "    )\n",
        "\n",
        "    # Measure execution time\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train_subset, y_train_subset)\n",
        "    execution_time = time.time() - start_time\n",
        "\n",
        "    # Calculate errors\n",
        "    train_score = model.score(X_train_subset, y_train_subset)\n",
        "    val_score = model.score(X_val_scaled, y_val)\n",
        "\n",
        "    train_error = 1 - train_score\n",
        "    val_error = 1 - val_score\n",
        "\n",
        "    results.append([data_size, config_name, f\"{train_error:.4f}\", f\"{val_error:.4f}\", f\"{execution_time:.3f}\"])\n",
        "\n",
        "# Display results\n",
        "headers = [\"Data size\", \"Configuration\", \"Training error\", \"Validation error\", \"Time of execution\"]\n",
        "print(tabulate(results, headers=headers, tablefmt=\"grid\"))"
      ]
    }
  ]
}